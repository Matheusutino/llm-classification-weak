{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>response</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>explanation</th>\n",
       "      <th>confidence</th>\n",
       "      <th>temperature</th>\n",
       "      <th>attempt</th>\n",
       "      <th>reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.txt</td>\n",
       "      <td>Rhetorical (Rhet) is a programming / knowledge...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>```json\\n{\\n  \"category\": \"Artificial Intellig...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>The text describes Rhetorical, a programming s...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>Reduction is the operation of transforming a p...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>\\n```json\\n{\\n  \"category\": \"Artificial Intell...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>The text discusses the concept of text classif...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.txt</td>\n",
       "      <td>For years, researchers have used knowledge-int...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>: \\n```json\\n{\\n  \"category\": \"Artificial Inte...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>The text discusses techniques used in natural ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.txt</td>\n",
       "      <td>Proceedings of a workshop held in conjunction ...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>```json\\n{\\n  \"category\": \"Artificial Intellig...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>The text mentions a workshop on Machine Learni...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.txt</td>\n",
       "      <td>The Medication Advisor is the latest project o...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>```json\\n{\\n  \"category\": \"Artificial Intellig...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>The text describes the development of an AI-po...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.446421</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name                                               text  \\\n",
       "0   126.txt  Rhetorical (Rhet) is a programming / knowledge...   \n",
       "1     5.txt  Reduction is the operation of transforming a p...   \n",
       "2    48.txt  For years, researchers have used knowledge-int...   \n",
       "3    81.txt  Proceedings of a workshop held in conjunction ...   \n",
       "4    25.txt  The Medication Advisor is the latest project o...   \n",
       "\n",
       "                     class                                           response  \\\n",
       "0  Artificial Intelligence  ```json\\n{\\n  \"category\": \"Artificial Intellig...   \n",
       "1  Artificial Intelligence  \\n```json\\n{\\n  \"category\": \"Artificial Intell...   \n",
       "2  Artificial Intelligence  : \\n```json\\n{\\n  \"category\": \"Artificial Inte...   \n",
       "3  Artificial Intelligence  ```json\\n{\\n  \"category\": \"Artificial Intellig...   \n",
       "4  Artificial Intelligence  ```json\\n{\\n  \"category\": \"Artificial Intellig...   \n",
       "\n",
       "           predicted_class                                        explanation  \\\n",
       "0  Artificial Intelligence  The text describes Rhetorical, a programming s...   \n",
       "1  Artificial Intelligence  The text discusses the concept of text classif...   \n",
       "2  Artificial Intelligence  The text discusses techniques used in natural ...   \n",
       "3  Artificial Intelligence  The text mentions a workshop on Machine Learni...   \n",
       "4  Artificial Intelligence  The text describes the development of an AI-po...   \n",
       "\n",
       "   confidence  temperature  attempt  reasoning  \n",
       "0         5.0     0.000000      0.0        NaN  \n",
       "1         5.0     0.000000      0.0        NaN  \n",
       "2         5.0     0.000000      0.0        NaN  \n",
       "3         5.0     0.550059      2.0        NaN  \n",
       "4         5.0     0.446421      2.0        NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/llm_predict/zero_shot/CSTR/gemma-2-9b-it.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_name          0\n",
       "text               0\n",
       "class              0\n",
       "response           0\n",
       "predicted_class    0\n",
       "explanation        0\n",
       "confidence         0\n",
       "temperature        0\n",
       "attempt            0\n",
       "reasoning          5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/Desktop/Itens./Itens/Projetos/paper-weak-llm/weak/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-04 14:13:53 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m llm = \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Name or path of your model\u001b[39;00m\n\u001b[32m      3\u001b[39m llm.apply_model(\u001b[38;5;28;01mlambda\u001b[39;00m model: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(model)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Itens./Itens/Projetos/paper-weak-llm/weak/lib/python3.12/site-packages/vllm/entrypoints/llm.py:273\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model, task, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, override_pooler_config, compilation_config, **kwargs)\u001b[39m\n\u001b[32m    243\u001b[39m engine_args = EngineArgs(\n\u001b[32m    244\u001b[39m     model=model,\n\u001b[32m    245\u001b[39m     task=task,\n\u001b[32m   (...)\u001b[39m\u001b[32m    269\u001b[39m     **kwargs,\n\u001b[32m    270\u001b[39m )\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# Create the Engine (autoselects V0 vs V1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_engine = \u001b[43mLLMEngine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUsageContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_class = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm_engine)\n\u001b[32m    277\u001b[39m \u001b[38;5;28mself\u001b[39m.request_counter = Counter()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Itens./Itens/Projetos/paper-weak-llm/weak/lib/python3.12/site-packages/vllm/engine/llm_engine.py:490\u001b[39m, in \u001b[36mLLMEngine.from_engine_args\u001b[39m\u001b[34m(cls, engine_args, usage_context, stat_loggers)\u001b[39m\n\u001b[32m    488\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates an LLM engine from the engine arguments.\"\"\"\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[38;5;66;03m# Create the engine configs.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m vllm_config = \u001b[43mengine_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_engine_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m engine_cls = \u001b[38;5;28mcls\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m envs.VLLM_USE_V1:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Itens./Itens/Projetos/paper-weak-llm/weak/lib/python3.12/site-packages/vllm/engine/arg_utils.py:1004\u001b[39m, in \u001b[36mEngineArgs.create_engine_config\u001b[39m\u001b[34m(self, usage_context, headless)\u001b[39m\n\u001b[32m   1000\u001b[39m current_platform.pre_register_and_update()\n\u001b[32m   1002\u001b[39m device_config = DeviceConfig(\n\u001b[32m   1003\u001b[39m     device=cast(Device, current_platform.device_type))\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m model_config = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_model_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[38;5;66;03m# * If VLLM_USE_V1 is unset, we enable V1 for \"supported features\"\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[38;5;66;03m#   and fall back to V0 for experimental or unsupported features.\u001b[39;00m\n\u001b[32m   1008\u001b[39m \u001b[38;5;66;03m# * If VLLM_USE_V1=1, we enable V1 for supported + experimental\u001b[39;00m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m#   features and raise error for unsupported features.\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# * If VLLM_USE_V1=0, we disable V1.\u001b[39;00m\n\u001b[32m   1011\u001b[39m use_v1 = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Itens./Itens/Projetos/paper-weak-llm/weak/lib/python3.12/site-packages/vllm/engine/arg_utils.py:862\u001b[39m, in \u001b[36mEngineArgs.create_model_config\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_model_config\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ModelConfig:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# gguf file needs a specific model loader and doesn't use hf_repo\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcheck_gguf_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    863\u001b[39m         \u001b[38;5;28mself\u001b[39m.quantization = \u001b[38;5;28mself\u001b[39m.load_format = \u001b[33m\"\u001b[39m\u001b[33mgguf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    865\u001b[39m     \u001b[38;5;66;03m# NOTE: This is to allow model loading from S3 in CI\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Itens./Itens/Projetos/paper-weak-llm/weak/lib/python3.12/site-packages/vllm/transformers_utils/utils.py:22\u001b[39m, in \u001b[36mcheck_gguf_file\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_gguf_file\u001b[39m(model: Union[\u001b[38;5;28mstr\u001b[39m, PathLike]) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check if the file is a GGUF model.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     model = \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model.is_file():\n\u001b[32m     24\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pathlib.py:1164\u001b[39m, in \u001b[36mPath.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1161\u001b[39m     msg = (\u001b[33m\"\u001b[39m\u001b[33msupport for supplying keyword arguments to pathlib.PurePath \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1162\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mis deprecated and scheduled for removal in Python \u001b[39m\u001b[38;5;132;01m{remove}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1163\u001b[39m     warnings._deprecated(\u001b[33m\"\u001b[39m\u001b[33mpathlib.PurePath(**kwargs)\u001b[39m\u001b[33m\"\u001b[39m, msg, remove=(\u001b[32m3\u001b[39m, \u001b[32m14\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1164\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pathlib.py:373\u001b[39m, in \u001b[36mPurePath.__init__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    371\u001b[39m             path = arg\n\u001b[32m    372\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    374\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33margument should be a str or an os.PathLike \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    375\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mobject where __fspath__ returns a str, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    376\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(path).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    377\u001b[39m         paths.append(path)\n\u001b[32m    378\u001b[39m \u001b[38;5;28mself\u001b[39m._raw_paths = paths\n",
      "\u001b[31mTypeError\u001b[39m: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'ellipsis'"
     ]
    }
   ],
   "source": [
    "from vllm import LLM\n",
    "llm = LLM(model=...)  # Name or path of your model\n",
    "llm.apply_model(lambda model: print(type(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/Desktop/Itens./Itens/Projetos/paper-weak-llm/weak/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re8.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 7674\n",
      "  Quantil 95% de tokens: 380.00\n",
      "  Total de tokens: 911639\n",
      "\n",
      "sms_spam.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 5574\n",
      "  Quantil 95% de tokens: 61.00\n",
      "  Total de tokens: 134116\n",
      "\n",
      "review_polarity.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 2000\n",
      "  Quantil 95% de tokens: 1538.90\n",
      "  Total de tokens: 1702361\n",
      "\n",
      "Dmoz-Health.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 6500\n",
      "  Quantil 95% de tokens: 48.00\n",
      "  Total de tokens: 192907\n",
      "\n",
      "classic4.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 7095\n",
      "  Quantil 95% de tokens: 335.30\n",
      "  Total de tokens: 964255\n",
      "\n",
      "webkb-parsed.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 8282\n",
      "  Quantil 95% de tokens: 1754.00\n",
      "  Total de tokens: 4938794\n",
      "\n",
      "NSF.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 10524\n",
      "  Quantil 95% de tokens: 26.00\n",
      "  Total de tokens: 141216\n",
      "\n",
      "Dmoz-Computers.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 9500\n",
      "  Quantil 95% de tokens: 49.00\n",
      "  Total de tokens: 257372\n",
      "\n",
      "Industry Sector.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 8817\n",
      "  Quantil 95% de tokens: 2024.00\n",
      "  Total de tokens: 5256310\n",
      "\n",
      "Dmoz-Science.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 6000\n",
      "  Quantil 95% de tokens: 52.00\n",
      "  Total de tokens: 181185\n",
      "\n",
      "SyskillWebert.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 333\n",
      "  Quantil 95% de tokens: 1536.60\n",
      "  Total de tokens: 187857\n",
      "\n",
      "CSTR.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 299\n",
      "  Quantil 95% de tokens: 408.90\n",
      "  Total de tokens: 62710\n",
      "\n",
      "Dmoz-Sports.csv:\n",
      "  Coluna de texto: text\n",
      "  Textos analisados: 13500\n",
      "  Quantil 95% de tokens: 45.00\n",
      "  Total de tokens: 360327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "# Caminho para os datasets\n",
    "dataset_dir = Path(\"datasets/original\")\n",
    "\n",
    "# Carrega o tokenizer\n",
    "tokenizer = Tokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
    "\n",
    "# Itera sobre todos os arquivos .csv na pasta\n",
    "for csv_file in dataset_dir.glob(\"*.csv\"):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        if 'class' not in df.columns:\n",
    "            print(f\"{csv_file.name}: coluna 'class' não encontrada.\")\n",
    "            continue\n",
    "\n",
    "        # Identifica colunas textuais\n",
    "        text_col_candidates = [col for col in df.columns if df[col].dtype == object and df[col].notna().any()]\n",
    "        if not text_col_candidates:\n",
    "            print(f\"{csv_file.name}: nenhuma coluna de texto encontrada.\")\n",
    "            continue\n",
    "\n",
    "        # Usa 'text' se disponível, senão o primeiro candidato\n",
    "        text_col = 'text' if 'text' in text_col_candidates else text_col_candidates[0]\n",
    "\n",
    "        # Tokeniza os textos válidos\n",
    "        texts = df[text_col].dropna().astype(str)\n",
    "        token_counts = [len(tokenizer.encode(text).ids) for text in texts]\n",
    "\n",
    "        q95 = np.percentile(token_counts, 95)\n",
    "        total_tokens = sum(token_counts)\n",
    "\n",
    "        print(f\"{csv_file.name}:\")\n",
    "        print(f\"  Coluna de texto: {text_col}\")\n",
    "        print(f\"  Textos analisados: {len(token_counts)}\")\n",
    "        print(f\"  Quantil 95% de tokens: {q95:.2f}\")\n",
    "        print(f\"  Total de tokens: {total_tokens}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {csv_file.name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/Desktop/Itens./Itens/Projetos/paper-weak-llm/weak/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=2, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tokenizers\n",
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
    "tokenizer.encode(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho de entrada\n",
    "input_path = \"datasets/original/sms_spam.csv\"\n",
    "\n",
    "# Caminho de saída\n",
    "output_path = \"sms_spam.csv\"\n",
    "\n",
    "# Ler o CSV\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "df['class'] = df['class'].map({1: 'spam', 0: 'ham'})\n",
    "\n",
    "# Salvar o DataFrame limpo\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>explanation</th>\n",
       "      <th>confidence</th>\n",
       "      <th>temperature</th>\n",
       "      <th>attempt</th>\n",
       "      <th>reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.txt</td>\n",
       "      <td>Rhetorical (Rhet) is a programming / knowledge...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>The text describes Rhet as a programming syste...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.txt</td>\n",
       "      <td>Reduction is the operation of transforming a p...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>The text discusses Linear Context-Free Rewriti...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name                                               text  \\\n",
       "0   126.txt  Rhetorical (Rhet) is a programming / knowledge...   \n",
       "1     5.txt  Reduction is the operation of transforming a p...   \n",
       "\n",
       "                     class          predicted_class  \\\n",
       "0  Artificial Intelligence  Artificial Intelligence   \n",
       "1  Artificial Intelligence  Artificial Intelligence   \n",
       "\n",
       "                                         explanation  confidence  temperature  \\\n",
       "0  The text describes Rhet as a programming syste...         5.0          0.0   \n",
       "1  The text discusses Linear Context-Free Rewriti...         4.0          0.0   \n",
       "\n",
       "   attempt  reasoning  \n",
       "0      1.0        NaN  \n",
       "1      1.0        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/llm_predict/zero_shot/CSTR/deepseek-r1-0528-qwen3-8b:free.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelA\n",
      "modelB\n"
     ]
    }
   ],
   "source": [
    "model_name = \"namespace/modelA\"\n",
    "model_id = model_name.split(\"/\")[-1]\n",
    "print(model_id)  # Output: modelA\n",
    "\n",
    "model_name = \"modelB\"\n",
    "model_id = model_name.split(\"/\")[-1]\n",
    "print(model_id)  # Output: modelB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/Desktop/Itens./Itens/Projetos/paper-weak-llm/weak/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'Responda o usuário'}, {'role': 'user', 'content': 'Olá'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá! Como posso ajudar você hoje?'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.core.predictors.predictor_manager import PredictionManager\n",
    "from src.core.messages.message_manager import MessageManager\n",
    "\n",
    "service = \"openrouter\"\n",
    "model_name = \"openrouter/cypher-alpha:free\"\n",
    "\n",
    "prediction_manager = PredictionManager(service=service, model_name=model_name)\n",
    "message_manager = MessageManager(message_type=\"openai\")\n",
    "\n",
    "user_prompt = \"Olá\"\n",
    "system_prompt = \"Responda o usuário\"\n",
    "\n",
    "message = message_manager.generate_message(user_prompt, system_prompt)\n",
    "\n",
    "print(message)\n",
    "\n",
    "result = prediction_manager.predict(messages=message, max_tokens=1000, temperature=0, seed =0)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF gerado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title, ax):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "def compute_confusion_matrices_and_f1(few_shot_root, zero_shot_root, output_pdf):\n",
    "    results = []\n",
    "    \n",
    "    with PdfPages(output_pdf) as pdf:\n",
    "        for dataset_folder in os.listdir(few_shot_root):\n",
    "            few_shot_dataset_path = os.path.join(few_shot_root, dataset_folder)\n",
    "            zero_shot_dataset_path = os.path.join(zero_shot_root, dataset_folder)\n",
    "            \n",
    "            if not os.path.isdir(few_shot_dataset_path) or not os.path.isdir(zero_shot_dataset_path):\n",
    "                continue\n",
    "            \n",
    "            for model_folder in os.listdir(few_shot_dataset_path):\n",
    "                few_shot_model_path = os.path.join(few_shot_dataset_path, model_folder)\n",
    "                zero_shot_file_path = os.path.join(zero_shot_dataset_path, f\"{model_folder}.csv\")\n",
    "                \n",
    "                if not os.path.isdir(few_shot_model_path) or not os.path.exists(zero_shot_file_path):\n",
    "                    continue\n",
    "                \n",
    "                few_shot_files = [f for f in os.listdir(few_shot_model_path) if f.endswith(\"test.csv\")]\n",
    "                \n",
    "                for file in few_shot_files:\n",
    "                    few_shot_file_path = os.path.join(few_shot_model_path, file)\n",
    "                    \n",
    "                    df_few_shot = pd.read_csv(few_shot_file_path)\n",
    "                    df_zero_shot = pd.read_csv(zero_shot_file_path)\n",
    "                    \n",
    "                    df_few_shot['class'] = df_few_shot['class'].astype(str)\n",
    "                    df_few_shot['predicted_class'] = df_few_shot['predicted_class'].astype(str)\n",
    "                    df_zero_shot['class'] = df_zero_shot['class'].astype(str)\n",
    "                    df_zero_shot['predicted_class'] = df_zero_shot['predicted_class'].astype(str)\n",
    "                    \n",
    "                    common_instances = df_few_shot.merge(df_zero_shot, on='file_name', suffixes=('_few_shot', '_zero_shot'))\n",
    "                    \n",
    "                    if not common_instances.empty:\n",
    "                        y_true_zero_shot = common_instances['class_zero_shot']\n",
    "                        y_pred_zero_shot = common_instances['predicted_class_zero_shot']\n",
    "                        y_true_few_shot = common_instances['class_few_shot']\n",
    "                        y_pred_few_shot = common_instances['predicted_class_few_shot']\n",
    "                        \n",
    "                        f1_few_shot = f1_score(y_true_few_shot, y_pred_few_shot, average='macro')\n",
    "                        f1_zero_shot = f1_score(y_true_zero_shot, y_pred_zero_shot, average='macro')\n",
    "                        \n",
    "                        all_labels = sorted(set(y_true_zero_shot) | set(y_pred_zero_shot) | set(y_true_few_shot) | set(y_pred_few_shot))\n",
    "                        cm_zero_shot = confusion_matrix(y_true_zero_shot, y_pred_zero_shot, labels=all_labels)\n",
    "                        cm_few_shot = confusion_matrix(y_true_few_shot, y_pred_few_shot, labels=all_labels)\n",
    "                        \n",
    "                        results.append({\n",
    "                            'dataset': dataset_folder,\n",
    "                            'model': model_folder,\n",
    "                            'f1_zero_shot': f1_zero_shot,\n",
    "                            'f1_few_shot': f1_few_shot,\n",
    "                        })\n",
    "                        \n",
    "                        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "                        plot_confusion_matrix(cm_zero_shot, all_labels, f\"Zero-Shot - {model_folder}\", axes[0])\n",
    "                        plot_confusion_matrix(cm_few_shot, all_labels, f\"Few-Shot - {model_folder}\", axes[1])\n",
    "                        \n",
    "                        plt.suptitle(f\"Dataset: {dataset_folder}\\nF1 Zero-Shot: {f1_zero_shot:.4f} | F1 Few-Shot: {f1_few_shot:.4f}\")\n",
    "                        pdf.savefig(fig)\n",
    "                        plt.close()\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Exemplo de uso\n",
    "few_shot_root = \"datasets/llm_predict/few_shot\"\n",
    "zero_shot_root = \"datasets/llm_predict/zero_shot\"\n",
    "output_pdf = \"confusion_matrices.pdf\"\n",
    "\n",
    "results = compute_confusion_matrices_and_f1(few_shot_root, zero_shot_root, output_pdf)\n",
    "print(\"PDF gerado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/llm_predict/zero_shot/review_polarity/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/review_polarity/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/review_polarity/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/review_polarity/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/review_polarity/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/review_polarity/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/review_polarity/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/review_polarity/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/review_polarity/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/review_polarity/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/NSF/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/NSF/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/NSF/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/NSF/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/NSF/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/NSF/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/NSF/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/NSF/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/NSF/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/NSF/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/SyskillWebert/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/SyskillWebert/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/SyskillWebert/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/SyskillWebert/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/SyskillWebert/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/SyskillWebert/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/SyskillWebert/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/SyskillWebert/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/SyskillWebert/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/SyskillWebert/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/CSTR/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/CSTR/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/CSTR/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/CSTR/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/CSTR/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/CSTR/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/CSTR/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/CSTR/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/CSTR/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/CSTR/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Computers/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Computers/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Computers/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Computers/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Computers/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Computers/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Computers/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Computers/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Computers/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Computers/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/classic4/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/classic4/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/classic4/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/classic4/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/classic4/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/classic4/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/classic4/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/classic4/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/classic4/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/classic4/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Science/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Science/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Science/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Science/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Science/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Science/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Science/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Science/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Science/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Science/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/webkb-parsed/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/webkb-parsed/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/webkb-parsed/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/webkb-parsed/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/webkb-parsed/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/webkb-parsed/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/webkb-parsed/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/webkb-parsed/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/webkb-parsed/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/webkb-parsed/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Sports/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Sports/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Sports/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Sports/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Sports/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Sports/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Sports/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Sports/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Sports/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Sports/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Health/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Health/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Health/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Health/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Health/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Health/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Health/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Health/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/Dmoz-Health/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/Dmoz-Health/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/Industry Sector/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/Industry Sector/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/Industry Sector/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/Industry Sector/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/Industry Sector/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/Industry Sector/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/Industry Sector/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/Industry Sector/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/Industry Sector/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/Industry Sector/llama3.2:3b/llama3.2:3b_test.csv\n",
      "datasets/llm_predict/zero_shot/re8/aya-expanse:8b.csv\n",
      "datasets/llm_predict/few_shot/re8/aya-expanse:8b/aya-expanse:8b_test.csv\n",
      "datasets/llm_predict/zero_shot/re8/mistral:7b.csv\n",
      "datasets/llm_predict/few_shot/re8/mistral:7b/mistral:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/re8/gemma2:2b.csv\n",
      "datasets/llm_predict/few_shot/re8/gemma2:2b/gemma2:2b_test.csv\n",
      "datasets/llm_predict/zero_shot/re8/qwen2.5:7b.csv\n",
      "datasets/llm_predict/few_shot/re8/qwen2.5:7b/qwen2.5:7b_test.csv\n",
      "datasets/llm_predict/zero_shot/re8/llama3.2:3b.csv\n",
      "datasets/llm_predict/few_shot/re8/llama3.2:3b/llama3.2:3b_test.csv\n",
      "Folder: CSTR\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CSTR</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.339326</td>\n",
       "      <td>0.344370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CSTR</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.315562</td>\n",
       "      <td>0.315954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CSTR</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.305528</td>\n",
       "      <td>0.309626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CSTR</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.302346</td>\n",
       "      <td>0.310109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CSTR</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.249340</td>\n",
       "      <td>0.262155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset           model  f1_zero_shot  f1_few_shot\n",
       "17    CSTR       gemma2:2b      0.339326     0.344370\n",
       "16    CSTR      mistral:7b      0.315562     0.315954\n",
       "15    CSTR  aya-expanse:8b      0.305528     0.309626\n",
       "18    CSTR      qwen2.5:7b      0.302346     0.310109\n",
       "19    CSTR     llama3.2:3b      0.249340     0.262155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: Dmoz-Computers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dmoz-Computers</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.372136</td>\n",
       "      <td>0.372231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dmoz-Computers</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.364663</td>\n",
       "      <td>0.364789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dmoz-Computers</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.358082</td>\n",
       "      <td>0.358286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dmoz-Computers</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.289812</td>\n",
       "      <td>0.289812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dmoz-Computers</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.274910</td>\n",
       "      <td>0.275900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset           model  f1_zero_shot  f1_few_shot\n",
       "20  Dmoz-Computers  aya-expanse:8b      0.372136     0.372231\n",
       "21  Dmoz-Computers      mistral:7b      0.364663     0.364789\n",
       "23  Dmoz-Computers      qwen2.5:7b      0.358082     0.358286\n",
       "22  Dmoz-Computers       gemma2:2b      0.289812     0.289812\n",
       "24  Dmoz-Computers     llama3.2:3b      0.274910     0.275900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: Dmoz-Health\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Dmoz-Health</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.605100</td>\n",
       "      <td>0.605034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Dmoz-Health</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.592502</td>\n",
       "      <td>0.592502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Dmoz-Health</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.566076</td>\n",
       "      <td>0.565959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Dmoz-Health</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.514737</td>\n",
       "      <td>0.515034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Dmoz-Health</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.431498</td>\n",
       "      <td>0.437633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset           model  f1_zero_shot  f1_few_shot\n",
       "45  Dmoz-Health  aya-expanse:8b      0.605100     0.605034\n",
       "48  Dmoz-Health      qwen2.5:7b      0.592502     0.592502\n",
       "46  Dmoz-Health      mistral:7b      0.566076     0.565959\n",
       "47  Dmoz-Health       gemma2:2b      0.514737     0.515034\n",
       "49  Dmoz-Health     llama3.2:3b      0.431498     0.437633"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: Dmoz-Science\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dmoz-Science</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.538704</td>\n",
       "      <td>0.538822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dmoz-Science</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.506031</td>\n",
       "      <td>0.505693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Dmoz-Science</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.495952</td>\n",
       "      <td>0.496034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dmoz-Science</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.447095</td>\n",
       "      <td>0.447095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Dmoz-Science</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.438569</td>\n",
       "      <td>0.441363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset           model  f1_zero_shot  f1_few_shot\n",
       "33  Dmoz-Science      qwen2.5:7b      0.538704     0.538822\n",
       "31  Dmoz-Science      mistral:7b      0.506031     0.505693\n",
       "30  Dmoz-Science  aya-expanse:8b      0.495952     0.496034\n",
       "32  Dmoz-Science       gemma2:2b      0.447095     0.447095\n",
       "34  Dmoz-Science     llama3.2:3b      0.438569     0.441363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: Dmoz-Sports\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Dmoz-Sports</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.793110</td>\n",
       "      <td>0.792799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Dmoz-Sports</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.791802</td>\n",
       "      <td>0.791825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dmoz-Sports</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.783147</td>\n",
       "      <td>0.783053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Dmoz-Sports</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.737393</td>\n",
       "      <td>0.737058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Dmoz-Sports</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.717793</td>\n",
       "      <td>0.718748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset           model  f1_zero_shot  f1_few_shot\n",
       "41  Dmoz-Sports      mistral:7b      0.793110     0.792799\n",
       "40  Dmoz-Sports  aya-expanse:8b      0.791802     0.791825\n",
       "43  Dmoz-Sports      qwen2.5:7b      0.783147     0.783053\n",
       "42  Dmoz-Sports       gemma2:2b      0.737393     0.737058\n",
       "44  Dmoz-Sports     llama3.2:3b      0.717793     0.718748"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: Industry Sector\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Industry Sector</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.337933</td>\n",
       "      <td>0.337334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Industry Sector</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.335390</td>\n",
       "      <td>0.333974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Industry Sector</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.321544</td>\n",
       "      <td>0.321200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Industry Sector</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.204734</td>\n",
       "      <td>0.207781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Industry Sector</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.146699</td>\n",
       "      <td>0.146615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset           model  f1_zero_shot  f1_few_shot\n",
       "53  Industry Sector      qwen2.5:7b      0.337933     0.337334\n",
       "51  Industry Sector      mistral:7b      0.335390     0.333974\n",
       "50  Industry Sector  aya-expanse:8b      0.321544     0.321200\n",
       "54  Industry Sector     llama3.2:3b      0.204734     0.207781\n",
       "52  Industry Sector       gemma2:2b      0.146699     0.146615"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: NSF\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NSF</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.595625</td>\n",
       "      <td>0.595416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NSF</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.588913</td>\n",
       "      <td>0.589180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NSF</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.577246</td>\n",
       "      <td>0.575305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NSF</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.505385</td>\n",
       "      <td>0.504709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NSF</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.493775</td>\n",
       "      <td>0.491400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset           model  f1_zero_shot  f1_few_shot\n",
       "5     NSF  aya-expanse:8b      0.595625     0.595416\n",
       "8     NSF      qwen2.5:7b      0.588913     0.589180\n",
       "6     NSF      mistral:7b      0.577246     0.575305\n",
       "7     NSF       gemma2:2b      0.505385     0.504709\n",
       "9     NSF     llama3.2:3b      0.493775     0.491400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: SyskillWebert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SyskillWebert</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.612163</td>\n",
       "      <td>0.593441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SyskillWebert</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.521121</td>\n",
       "      <td>0.508093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SyskillWebert</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.443769</td>\n",
       "      <td>0.523222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SyskillWebert</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.352096</td>\n",
       "      <td>0.440510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SyskillWebert</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.275193</td>\n",
       "      <td>0.330124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset           model  f1_zero_shot  f1_few_shot\n",
       "13  SyskillWebert      qwen2.5:7b      0.612163     0.593441\n",
       "11  SyskillWebert      mistral:7b      0.521121     0.508093\n",
       "10  SyskillWebert  aya-expanse:8b      0.443769     0.523222\n",
       "14  SyskillWebert     llama3.2:3b      0.352096     0.440510\n",
       "12  SyskillWebert       gemma2:2b      0.275193     0.330124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: classic4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>classic4</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.545448</td>\n",
       "      <td>0.545532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>classic4</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.518508</td>\n",
       "      <td>0.518341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>classic4</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.396244</td>\n",
       "      <td>0.394809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>classic4</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.349733</td>\n",
       "      <td>0.350317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>classic4</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.173747</td>\n",
       "      <td>0.174105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset           model  f1_zero_shot  f1_few_shot\n",
       "28  classic4      qwen2.5:7b      0.545448     0.545532\n",
       "26  classic4      mistral:7b      0.518508     0.518341\n",
       "25  classic4  aya-expanse:8b      0.396244     0.394809\n",
       "27  classic4       gemma2:2b      0.349733     0.350317\n",
       "29  classic4     llama3.2:3b      0.173747     0.174105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: re8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>re8</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>0.728099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>re8</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.494022</td>\n",
       "      <td>0.490624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>re8</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.464090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>re8</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.434793</td>\n",
       "      <td>0.434656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>re8</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.224041</td>\n",
       "      <td>0.224041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset           model  f1_zero_shot  f1_few_shot\n",
       "58     re8      qwen2.5:7b      0.728099     0.728099\n",
       "59     re8     llama3.2:3b      0.494022     0.490624\n",
       "55     re8  aya-expanse:8b      0.464100     0.464090\n",
       "56     re8      mistral:7b      0.434793     0.434656\n",
       "57     re8       gemma2:2b      0.224041     0.224041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: review_polarity\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>review_polarity</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.952207</td>\n",
       "      <td>0.952207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>review_polarity</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.902149</td>\n",
       "      <td>0.902149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>review_polarity</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.630641</td>\n",
       "      <td>0.630641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>review_polarity</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.622865</td>\n",
       "      <td>0.619244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review_polarity</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.610483</td>\n",
       "      <td>0.916015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset           model  f1_zero_shot  f1_few_shot\n",
       "0  review_polarity  aya-expanse:8b      0.952207     0.952207\n",
       "2  review_polarity       gemma2:2b      0.902149     0.902149\n",
       "3  review_polarity      qwen2.5:7b      0.630641     0.630641\n",
       "4  review_polarity     llama3.2:3b      0.622865     0.619244\n",
       "1  review_polarity      mistral:7b      0.610483     0.916015"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Folder: webkb-parsed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>f1_zero_shot</th>\n",
       "      <th>f1_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>webkb-parsed</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>0.471704</td>\n",
       "      <td>0.471823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>webkb-parsed</td>\n",
       "      <td>aya-expanse:8b</td>\n",
       "      <td>0.450676</td>\n",
       "      <td>0.450363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>webkb-parsed</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>0.433926</td>\n",
       "      <td>0.437715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>webkb-parsed</td>\n",
       "      <td>gemma2:2b</td>\n",
       "      <td>0.431301</td>\n",
       "      <td>0.430953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>webkb-parsed</td>\n",
       "      <td>llama3.2:3b</td>\n",
       "      <td>0.322208</td>\n",
       "      <td>0.370539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dataset           model  f1_zero_shot  f1_few_shot\n",
       "38  webkb-parsed      qwen2.5:7b      0.471704     0.471823\n",
       "35  webkb-parsed  aya-expanse:8b      0.450676     0.450363\n",
       "36  webkb-parsed      mistral:7b      0.433926     0.437715\n",
       "37  webkb-parsed       gemma2:2b      0.431301     0.430953\n",
       "39  webkb-parsed     llama3.2:3b      0.322208     0.370539"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_f1_for_common_instances(few_shot_root, zero_shot_root):\n",
    "    results = []\n",
    "    \n",
    "    for dataset_folder in os.listdir(few_shot_root):\n",
    "        few_shot_dataset_path = os.path.join(few_shot_root, dataset_folder)\n",
    "        zero_shot_dataset_path = os.path.join(zero_shot_root, dataset_folder)\n",
    "        \n",
    "        if not os.path.isdir(few_shot_dataset_path) or not os.path.isdir(zero_shot_dataset_path):\n",
    "            continue\n",
    "        \n",
    "        for model_folder in os.listdir(few_shot_dataset_path):\n",
    "            few_shot_model_path = os.path.join(few_shot_dataset_path, model_folder)\n",
    "            zero_shot_file_path = os.path.join(zero_shot_dataset_path, f\"{model_folder}.csv\")\n",
    "            \n",
    "            if not os.path.isdir(few_shot_model_path) or not os.path.exists(zero_shot_file_path):\n",
    "                continue\n",
    "            \n",
    "            few_shot_files = [f for f in os.listdir(few_shot_model_path) if f.endswith(\"test.csv\")]\n",
    "            \n",
    "            for file in few_shot_files:\n",
    "                few_shot_file_path = os.path.join(few_shot_model_path, file)\n",
    "                \n",
    "                df_few_shot = pd.read_csv(few_shot_file_path)\n",
    "                df_zero_shot = pd.read_csv(zero_shot_file_path)\n",
    "\n",
    "                df_few_shot['class'] = df_few_shot['class'].astype(str)\n",
    "                df_few_shot['predicted_class'] = df_few_shot['predicted_class'].astype(str)\n",
    "                \n",
    "                df_zero_shot['class'] = df_zero_shot['class'].astype(str)\n",
    "                df_zero_shot['predicted_class'] = df_zero_shot['predicted_class'].astype(str)\n",
    "                \n",
    "                common_instances = df_few_shot.merge(df_zero_shot, on='file_name', suffixes=('_few_shot', '_zero_shot'))\n",
    "                \n",
    "                if not common_instances.empty:\n",
    "                    f1_few_shot = f1_score(common_instances['class_few_shot'], common_instances['predicted_class_few_shot'], average='macro')\n",
    "                    f1_zero_shot = f1_score(common_instances['class_zero_shot'], common_instances['predicted_class_zero_shot'], average='macro')\n",
    "                    \n",
    "                    results.append({\n",
    "                        'dataset': dataset_folder,\n",
    "                        'model': model_folder,\n",
    "                        'f1_zero_shot': f1_zero_shot,\n",
    "                        'f1_few_shot': f1_few_shot,\n",
    "                    })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "# Exemplo de uso\n",
    "few_shot_root = \"datasets/llm_predict/few_shot\"\n",
    "zero_shot_root = \"datasets/llm_predict/zero_shot\"\n",
    "results = compute_f1_for_common_instances(few_shot_root, zero_shot_root)\n",
    "\n",
    "for dataset, group in results.groupby('dataset'):\n",
    "        print(f\"Folder: {dataset}\")\n",
    "        display(group.sort_values(by='f1_zero_shot', ascending=False))\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size:  1712\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN supervisionado Low</td>\n",
       "      <td>0.575518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semi-Supervisionado com Correção</td>\n",
       "      <td>0.701195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semi-Supervisionado com explanation</td>\n",
       "      <td>0.760743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semi-Supervisionado sem correção</td>\n",
       "      <td>0.669477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LLM Zero-Shot</td>\n",
       "      <td>0.710527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN Supervisionado</td>\n",
       "      <td>0.787565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Modelo  F1-score\n",
       "0               KNN supervisionado Low  0.575518\n",
       "1     Semi-Supervisionado com Correção  0.701195\n",
       "2  Semi-Supervisionado com explanation  0.760743\n",
       "3     Semi-Supervisionado sem correção  0.669477\n",
       "4                        LLM Zero-Shot  0.710527\n",
       "5                   KNN Supervisionado  0.787565"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "def load_and_preprocess_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df['predicted_class'] != \"other\"]\n",
    "    df = df.dropna(subset=['text'])\n",
    "    df['explanation'] = df['explanation'].fillna(\"\")\n",
    "    return df\n",
    "\n",
    "def generate_embeddings(df, model_name='all-MiniLM-L12-v2', normalize_embeddings=True):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    df['embedding'] = df['text'].apply(lambda x: model.encode(x, normalize_embeddings=normalize_embeddings).tolist())\n",
    "    df['explanation_embedding'] = df['explanation'].apply(lambda x: model.encode(x, normalize_embeddings=normalize_embeddings).tolist())\n",
    "\n",
    "    # Concatenar as embeddings de texto e explicação\n",
    "    df['combined_embedding'] = df.apply(lambda row: np.concatenate([row['embedding'], row['explanation_embedding']]), axis=1)\n",
    "    return df\n",
    "\n",
    "def apply_kmeans_clustering(df):\n",
    "    num_clusters = df['class'].nunique()\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(df['embedding'].tolist())\n",
    "    distances = euclidean_distances(df['embedding'].tolist(), kmeans.cluster_centers_)\n",
    "    return df, distances, kmeans\n",
    "\n",
    "\n",
    "def select_representative_instances(df, distances, num_clusters, m):\n",
    "    n = int(m * (len(df)/df['class'].nunique()))\n",
    "    selected_instances = []\n",
    "    for cluster_id in range(num_clusters):\n",
    "        cluster_indices = np.where(df['cluster'] == cluster_id)[0]\n",
    "        cluster_distances = distances[cluster_indices, cluster_id]\n",
    "        sorted_indices = cluster_indices[np.argsort(cluster_distances)]\n",
    "        selected_indices = np.concatenate([sorted_indices[:n//2], sorted_indices[-n//2:]])\n",
    "        selected_instances.append(df.iloc[selected_indices])\n",
    "    return pd.concat(selected_instances)\n",
    "\n",
    "def split_train_data(df, selected_instances, m_percent=0.7):\n",
    "    df_remaining = df.drop(selected_instances.index)\n",
    "    train_data = df_remaining.sample(frac=m_percent, random_state=42)\n",
    "    return train_data, df_remaining.drop(train_data.index)\n",
    "\n",
    "\n",
    "def train_and_refine_labels(selected_instances, train_data):\n",
    "    \"\"\"\n",
    "    Trains an auxiliary SVM model on selected instances and refines pseudo-labels in training data\n",
    "    \n",
    "    Args:\n",
    "        selected_instances (DataFrame): Labeled data with 'embedding' and 'class' columns\n",
    "        train_data (DataFrame): Unlabeled data with 'embedding' and 'predicted_class' columns\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Refined training data with consensus predictions\n",
    "    \"\"\"\n",
    "    # Train auxiliary model\n",
    "    aux_model = LinearSVC()\n",
    "    embeddings = np.array(selected_instances['embedding'].tolist())\n",
    "    aux_model.fit(embeddings, selected_instances['class'])\n",
    "    \n",
    "    # Refine pseudo-labels\n",
    "    train_embeddings = np.array(train_data['embedding'].tolist())\n",
    "    train_data = train_data.copy()\n",
    "    train_data['refined_predicted_class'] = aux_model.predict(train_embeddings)\n",
    "    \n",
    "    # Filter consensus predictions\n",
    "    consensus_mask = (train_data['predicted_class'] == train_data['refined_predicted_class'])\n",
    "    return train_data, train_data[consensus_mask].copy()\n",
    "\n",
    "def prepare_semi_supervised_data(selected_instances, train_data_consensus):\n",
    "    X_labeled = np.array(selected_instances['embedding'].tolist())\n",
    "    y_labeled = selected_instances['class'].values\n",
    "    X_pseudo = np.array(train_data_consensus['embedding'].tolist())\n",
    "    y_pseudo = train_data_consensus['refined_predicted_class'].values\n",
    "    return np.concatenate([X_labeled, X_pseudo]), np.concatenate([y_labeled, y_pseudo])\n",
    "\n",
    "\n",
    "def train_predict_evaluate(model, param_grid, X_train, y_train, X_test, y_test, cv=5):\n",
    "    le = LabelEncoder()\n",
    "    y_labeled = le.fit_transform(y_train)\n",
    "    grid_search = BayesSearchCV(model, param_grid, cv=cv, n_iter= 5, scoring='f1_weighted', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_labeled)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_transform = le.inverse_transform(y_pred)\n",
    "    f1 = f1_score(y_test, y_pred_transform, average='weighted')\n",
    "    \n",
    "    return f1\n",
    "\n",
    "m =  0.05 # Porcentagem de dados a serem escolhidos para rotulação seguindo o KMeans\n",
    "\n",
    "path = \"datasets/llm_predict/zero_shot/Dmoz-Science/qwq-32b.csv\"\n",
    "df = load_and_preprocess_data(path)\n",
    "df = generate_embeddings(df)\n",
    "df, distances, kmeans = apply_kmeans_clustering(df)\n",
    "selected_instances = select_representative_instances(df, distances, kmeans.n_clusters, m=m)\n",
    "train_data, eval_data = split_train_data(df, selected_instances)\n",
    "train_data_svm_pred, refined_data = train_and_refine_labels(selected_instances, train_data)\n",
    "X_train_semi, y_train_semi = prepare_semi_supervised_data(selected_instances, refined_data)\n",
    "\n",
    "X_eval = eval_data['embedding'].tolist()\n",
    "y_eval = eval_data['class'].tolist()\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(3, 10)),  # Número de vizinhos\n",
    "    'metric': ['euclidean', 'manhattan']  # Métrica de distância\n",
    "}\n",
    "\n",
    "# Supervised\n",
    "X_supervised = pd.concat([selected_instances['embedding'], train_data['embedding']]).tolist()\n",
    "y_supervised = pd.concat([selected_instances['class'], train_data['class']]).tolist()\n",
    "\n",
    "# Semi with explanation\n",
    "X_train_semi_explation = np.array(refined_data['combined_embedding'].tolist())\n",
    "y_train_semi_explation = refined_data['refined_predicted_class'].values\n",
    "\n",
    "# KMeans + SVM\n",
    "X_semi_svm = pd.concat([selected_instances['embedding'], train_data_svm_pred['embedding']]).tolist() \n",
    "y_semi_svm = pd.concat([selected_instances['class'], train_data_svm_pred['refined_predicted_class']]).tolist()\n",
    "\n",
    "# Only choosed by Kmeans\n",
    "X_supervised_low = selected_instances['embedding'].tolist()\n",
    "y_supervised_low = selected_instances['class'].tolist()\n",
    "\n",
    "# Métricas\n",
    "f1_supervised_low = train_predict_evaluate(model, param_grid, X_supervised_low, y_supervised_low, X_eval, y_eval)\n",
    "f1_semi = train_predict_evaluate(model, param_grid, X_train_semi, y_train_semi, X_eval, y_eval)\n",
    "f1_semi_explanation = train_predict_evaluate(model, param_grid, X_train_semi_explation, y_train_semi_explation, eval_data['combined_embedding'].tolist(), y_eval)\n",
    "f1_semi_svm = train_predict_evaluate(model, param_grid, X_semi_svm, y_semi_svm, X_eval, y_eval)\n",
    "f1_llm = f1_score(y_eval, eval_data['predicted_class'], average='weighted')\n",
    "f1_supervised = train_predict_evaluate(model, param_grid, X_supervised, y_supervised, X_eval, y_eval)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Modelo': ['KNN supervisionado Low', 'Semi-Supervisionado com Correção', 'Semi-Supervisionado com explanation', 'Semi-Supervisionado sem correção', 'LLM Zero-Shot', 'KNN Supervisionado'],\n",
    "    'F1-score': [f1_supervised_low, f1_semi, f1_semi_explanation, f1_semi_svm, f1_llm, f1_supervised]\n",
    "})\n",
    "print(\"Test size: \", len(eval_data))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, let's see. I need to solve the expression 2 plus 3 multiplied by 2. Hmm, right, I remember there's an order of operations you have to follow. What's that called again? Oh yeah, PEMDAS: Parentheses, Exponents, Multiplication and Division, Addition and Subtraction. So I should do the multiplication before the addition here.\\n\\nAlright, so first, the multiplication part is 3 times 2. Let me calculate that first. 3 multiplied by 2 is 6. Got that. Now, replace that back into the original problem. So instead of 2 + 3 * 2, it becomes 2 + 6. Now that's straightforward. Adding those together, 2 plus 6 equals 8. Wait, is that right? Let me double-check. If I had done the operations left to right without considering multiplication first, it would be 2 plus 3 first, which is 5, then 5 times 2 is 10. But that's different. Oh right, so order of operations is crucial here. Since multiplication comes before addition, the correct answer should indeed be 8. Yeah, I think that's correct. Let me confirm once more. 3 times 2 is 6, plus 2 is 8. Yep, that's definitely it. So the answer is 8.\\n</think>\\n\\nThe expression \\\\(2 + 3 \\\\times 2\\\\) is solved by following the order of operations (PEMDAS/BODMAS):\\n\\n1. **Multiplication first**:  \\n   \\\\(3 \\\\times 2 = 6\\\\).\\n\\n2. **Then add**:  \\n   \\\\(2 + 6 = 8\\\\).\\n\\n**Answer:**  \\n\\\\(\\\\boxed{8}\\\\)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = \"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\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"qwen/qwq-32b\",\n",
    "  messages=[{\"role\":\"system\",\"content\":\"2+ 3 * 2\"}],\n",
    "  temperature=0.6,\n",
    "  top_p=0.95,\n",
    "  max_tokens=4096,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size:  2449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN supervisionado Low</td>\n",
       "      <td>0.352835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semi-Supervisionado com Correção</td>\n",
       "      <td>0.467988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semi-Supervisionado com explanation</td>\n",
       "      <td>0.432550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semi-Supervisionado sem correção</td>\n",
       "      <td>0.482526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LLM Zero-Shot</td>\n",
       "      <td>0.399587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN Supervisionado</td>\n",
       "      <td>0.852126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Modelo  F1-score\n",
       "0               KNN supervisionado Low  0.352835\n",
       "1     Semi-Supervisionado com Correção  0.467988\n",
       "2  Semi-Supervisionado com explanation  0.432550\n",
       "3     Semi-Supervisionado sem correção  0.482526\n",
       "4                        LLM Zero-Shot  0.399587\n",
       "5                   KNN Supervisionado  0.852126"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "def load_and_preprocess_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df['predicted_class'] != \"other\"]\n",
    "    df = df.dropna(subset=['text'])\n",
    "    df['explanation'] = df['explanation'].fillna(\"\")\n",
    "    return df\n",
    "\n",
    "def generate_embeddings(df, model_name='all-MiniLM-L12-v2', normalize_embeddings=True):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    df['embedding'] = df['text'].apply(lambda x: model.encode(x, normalize_embeddings=normalize_embeddings).tolist())\n",
    "    df['explanation_embedding'] = df['explanation'].apply(lambda x: model.encode(x, normalize_embeddings=normalize_embeddings).tolist())\n",
    "\n",
    "    # Concatenar as embeddings de texto e explicação\n",
    "    df['combined_embedding'] = df.apply(lambda row: np.concatenate([row['embedding'], row['explanation_embedding']]), axis=1)\n",
    "    return df\n",
    "\n",
    "def apply_kmeans_clustering(df):\n",
    "    num_clusters = df['class'].nunique()\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(df['embedding'].tolist())\n",
    "    distances = euclidean_distances(df['embedding'].tolist(), kmeans.cluster_centers_)\n",
    "    return df, distances, kmeans\n",
    "\n",
    "\n",
    "def select_representative_instances(df, distances, num_clusters, m):\n",
    "    n = int(m * (len(df)/df['class'].nunique()))\n",
    "    selected_instances = []\n",
    "    for cluster_id in range(num_clusters):\n",
    "        cluster_indices = np.where(df['cluster'] == cluster_id)[0]\n",
    "        cluster_distances = distances[cluster_indices, cluster_id]\n",
    "        sorted_indices = cluster_indices[np.argsort(cluster_distances)]\n",
    "        #selected_indices = np.concatenate([sorted_indices[:n//2], sorted_indices[-n//2:]])\n",
    "        selected_indices = sorted_indices[:n]\n",
    "        selected_instances.append(df.iloc[selected_indices])\n",
    "    return pd.concat(selected_instances)\n",
    "\n",
    "def split_train_data(df, selected_instances, m_percent=0.7):\n",
    "    df_remaining = df.drop(selected_instances.index)\n",
    "    train_data = df_remaining.sample(frac=m_percent, random_state=42)\n",
    "    return train_data, df_remaining.drop(train_data.index)\n",
    "\n",
    "\n",
    "def train_and_refine_labels(selected_instances, train_data):\n",
    "    \"\"\"\n",
    "    Trains an auxiliary SVM model on selected instances and refines pseudo-labels in training data\n",
    "    \n",
    "    Args:\n",
    "        selected_instances (DataFrame): Labeled data with 'embedding' and 'class' columns\n",
    "        train_data (DataFrame): Unlabeled data with 'embedding' and 'predicted_class' columns\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Refined training data with consensus predictions\n",
    "    \"\"\"\n",
    "    # Train auxiliary model\n",
    "    aux_model = LinearSVC()\n",
    "    embeddings = np.array(selected_instances['embedding'].tolist())\n",
    "    aux_model.fit(embeddings, selected_instances['class'])\n",
    "    \n",
    "    # Refine pseudo-labels\n",
    "    train_embeddings = np.array(train_data['embedding'].tolist())\n",
    "    train_data = train_data.copy()\n",
    "    train_data['refined_predicted_class'] = aux_model.predict(train_embeddings)\n",
    "    \n",
    "    # Filter consensus predictions\n",
    "    consensus_mask = (train_data['predicted_class'] == train_data['refined_predicted_class'])\n",
    "    return train_data, train_data[consensus_mask].copy()\n",
    "\n",
    "def prepare_semi_supervised_data(selected_instances, train_data_consensus):\n",
    "    X_labeled = np.array(selected_instances['embedding'].tolist())\n",
    "    y_labeled = selected_instances['class'].values\n",
    "    X_pseudo = np.array(train_data_consensus['embedding'].tolist())\n",
    "    y_pseudo = train_data_consensus['refined_predicted_class'].values\n",
    "    return np.concatenate([X_labeled, X_pseudo]), np.concatenate([y_labeled, y_pseudo])\n",
    "\n",
    "\n",
    "def train_predict_evaluate(model, param_grid, X_train, y_train, X_test, y_test, cv=5):\n",
    "    le = LabelEncoder()\n",
    "    y_labeled = le.fit_transform(y_train)\n",
    "    grid_search = BayesSearchCV(model, param_grid, cv=cv, n_iter= 5, scoring='f1_weighted', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_labeled)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_transform = le.inverse_transform(y_pred)\n",
    "    f1 = f1_score(y_test, y_pred_transform, average='weighted')\n",
    "    \n",
    "    return f1\n",
    "\n",
    "m =  0.05 # Porcentagem de dados a serem escolhidos para rotulação seguindo o KMeans\n",
    "\n",
    "path = \"datasets/llm_predict/zero_shot/Industry Sector/qwen2.5:7b.csv\"\n",
    "df = load_and_preprocess_data(path)\n",
    "df = generate_embeddings(df)\n",
    "df, distances, kmeans = apply_kmeans_clustering(df)\n",
    "selected_instances = select_representative_instances(df, distances, kmeans.n_clusters, m=m)\n",
    "train_data, eval_data = split_train_data(df, selected_instances)\n",
    "train_data_svm_pred, refined_data = train_and_refine_labels(selected_instances, train_data)\n",
    "X_train_semi, y_train_semi = prepare_semi_supervised_data(selected_instances, refined_data)\n",
    "\n",
    "X_eval = eval_data['embedding'].tolist()\n",
    "y_eval = eval_data['class'].tolist()\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(3, 10)),  # Número de vizinhos\n",
    "    'metric': ['euclidean', 'manhattan']  # Métrica de distância\n",
    "}\n",
    "\n",
    "# Supervised\n",
    "X_supervised = pd.concat([selected_instances['embedding'], train_data['embedding']]).tolist()\n",
    "y_supervised = pd.concat([selected_instances['class'], train_data['class']]).tolist()\n",
    "\n",
    "# Semi with explanation\n",
    "X_train_semi_explation = np.array(refined_data['combined_embedding'].tolist())\n",
    "y_train_semi_explation = refined_data['refined_predicted_class'].values\n",
    "\n",
    "# KMeans + SVM\n",
    "X_semi_svm = pd.concat([selected_instances['embedding'], train_data_svm_pred['embedding']]).tolist() \n",
    "y_semi_svm = pd.concat([selected_instances['class'], train_data_svm_pred['refined_predicted_class']]).tolist()\n",
    "\n",
    "# Only choosed by Kmeans\n",
    "X_supervised_low = selected_instances['embedding'].tolist()\n",
    "y_supervised_low = selected_instances['class'].tolist()\n",
    "\n",
    "# Métricas\n",
    "f1_supervised_low = train_predict_evaluate(model, param_grid, X_supervised_low, y_supervised_low, X_eval, y_eval)\n",
    "f1_semi = train_predict_evaluate(model, param_grid, X_train_semi, y_train_semi, X_eval, y_eval)\n",
    "f1_semi_explanation = train_predict_evaluate(model, param_grid, X_train_semi_explation, y_train_semi_explation, eval_data['combined_embedding'].tolist(), y_eval)\n",
    "f1_semi_svm = train_predict_evaluate(model, param_grid, X_semi_svm, y_semi_svm, X_eval, y_eval)\n",
    "f1_llm = f1_score(y_eval, eval_data['predicted_class'], average='weighted')\n",
    "f1_supervised = train_predict_evaluate(model, param_grid, X_supervised, y_supervised, X_eval, y_eval)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Modelo': ['KNN supervisionado Low', 'Semi-Supervisionado com Correção', 'Semi-Supervisionado com explanation', 'Semi-Supervisionado sem correção', 'LLM Zero-Shot', 'KNN Supervisionado'],\n",
    "    'F1-score': [f1_supervised_low, f1_semi, f1_semi_explanation, f1_semi_svm, f1_llm, f1_supervised]\n",
    "})\n",
    "print(\"Test size: \", len(eval_data))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>embedding</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>earn.4911.txt</td>\n",
       "      <td>trinity industries inc trn sets quarterly qtly...</td>\n",
       "      <td>earn</td>\n",
       "      <td>[-0.14720497, 0.010837354, 0.02479065, -0.0330...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>earn.8511.txt</td>\n",
       "      <td>providence energy corp pvy regular dividend qt...</td>\n",
       "      <td>earn</td>\n",
       "      <td>[-0.13983874, 0.009222191, 0.06883508, -0.0065...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>earn.5684.txt</td>\n",
       "      <td>manufacturers hanover corp mhc sets dividend q...</td>\n",
       "      <td>earn</td>\n",
       "      <td>[-0.15036245, 0.021448446, 0.042295173, 0.0067...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>earn.7131.txt</td>\n",
       "      <td>coopervision inc eye qtly dividend shr cts vs ...</td>\n",
       "      <td>earn</td>\n",
       "      <td>[-0.15610632, 0.015163911, 0.03911728, -0.0339...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>earn.7493.txt</td>\n",
       "      <td>conagra inc cag regular dividend set qtly div ...</td>\n",
       "      <td>earn</td>\n",
       "      <td>[-0.14107798, 0.029511584, 0.017448528, -0.016...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>money_fx.5519.txt</td>\n",
       "      <td>u k money market receives mln stg assistance t...</td>\n",
       "      <td>money</td>\n",
       "      <td>[-0.021481989, -0.012907123, 0.022659488, 0.01...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>interest.1533.txt</td>\n",
       "      <td>bankers trust bt raises broker loan rate banke...</td>\n",
       "      <td>interest</td>\n",
       "      <td>[0.009739384, -0.105374366, -0.055346005, 0.00...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7183</th>\n",
       "      <td>money_fx.2009.txt</td>\n",
       "      <td>kuwaiti dinar rates firm aid window open inter...</td>\n",
       "      <td>money</td>\n",
       "      <td>[-0.06386504, -0.027708964, -0.01861818, 0.009...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>interest.5644.txt</td>\n",
       "      <td>u s fhl banks sets pct pct pct rates on billio...</td>\n",
       "      <td>interest</td>\n",
       "      <td>[0.03028964, -0.022710973, -0.058148254, 0.003...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>interest.2264.txt</td>\n",
       "      <td>top discount rate at u k bill tender rises to pct</td>\n",
       "      <td>interest</td>\n",
       "      <td>[-0.041372783, -0.055311393, 0.0013467374, -0....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name                                               text  \\\n",
       "4323      earn.4911.txt  trinity industries inc trn sets quarterly qtly...   \n",
       "6179      earn.8511.txt  providence energy corp pvy regular dividend qt...   \n",
       "4207      earn.5684.txt  manufacturers hanover corp mhc sets dividend q...   \n",
       "2733      earn.7131.txt  coopervision inc eye qtly dividend shr cts vs ...   \n",
       "5703      earn.7493.txt  conagra inc cag regular dividend set qtly div ...   \n",
       "...                 ...                                                ...   \n",
       "7003  money_fx.5519.txt  u k money market receives mln stg assistance t...   \n",
       "6738  interest.1533.txt  bankers trust bt raises broker loan rate banke...   \n",
       "7183  money_fx.2009.txt  kuwaiti dinar rates firm aid window open inter...   \n",
       "6723  interest.5644.txt  u s fhl banks sets pct pct pct rates on billio...   \n",
       "6777  interest.2264.txt  top discount rate at u k bill tender rises to pct   \n",
       "\n",
       "         class                                          embedding  cluster  \n",
       "4323      earn  [-0.14720497, 0.010837354, 0.02479065, -0.0330...        0  \n",
       "6179      earn  [-0.13983874, 0.009222191, 0.06883508, -0.0065...        0  \n",
       "4207      earn  [-0.15036245, 0.021448446, 0.042295173, 0.0067...        0  \n",
       "2733      earn  [-0.15610632, 0.015163911, 0.03911728, -0.0339...        0  \n",
       "5703      earn  [-0.14107798, 0.029511584, 0.017448528, -0.016...        0  \n",
       "...        ...                                                ...      ...  \n",
       "7003     money  [-0.021481989, -0.012907123, 0.022659488, 0.01...        7  \n",
       "6738  interest  [0.009739384, -0.105374366, -0.055346005, 0.00...        7  \n",
       "7183     money  [-0.06386504, -0.027708964, -0.01861818, 0.009...        7  \n",
       "6723  interest  [0.03028964, -0.022710973, -0.058148254, 0.003...        7  \n",
       "6777  interest  [-0.041372783, -0.055311393, 0.0013467374, -0....        7  \n",
       "\n",
       "[376 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing and evaluating model with ORIGINAL data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k value: 3\n",
      "Best cross-validation accuracy: 0.9708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.91      0.89      0.90      2292\n",
      "       crude       0.76      0.94      0.84       374\n",
      "        earn       0.94      0.95      0.95      3923\n",
      "       grain       0.00      0.00      0.00        51\n",
      "    interest       0.72      0.88      0.79       271\n",
      "       money       0.83      0.69      0.75       293\n",
      "        ship       0.00      0.00      0.00       144\n",
      "       trade       0.67      0.87      0.75       326\n",
      "\n",
      "    accuracy                           0.89      7674\n",
      "   macro avg       0.60      0.65      0.62      7674\n",
      "weighted avg       0.88      0.89      0.88      7674\n",
      "\n",
      "\n",
      "Optimizing and evaluating model with AUGMENTED data:\n",
      "Best k value: 5\n",
      "Best cross-validation accuracy: 0.9655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.92      0.90      0.91      2292\n",
      "       crude       0.81      0.92      0.86       374\n",
      "        earn       0.94      0.95      0.95      3923\n",
      "       grain       0.00      0.00      0.00        51\n",
      "    interest       0.77      0.85      0.81       271\n",
      "       money       0.62      0.75      0.68       293\n",
      "        ship       0.00      0.00      0.00       144\n",
      "       trade       0.68      0.86      0.76       326\n",
      "\n",
      "    accuracy                           0.90      7674\n",
      "   macro avg       0.59      0.65      0.62      7674\n",
      "weighted avg       0.88      0.90      0.89      7674\n",
      "\n",
      "\n",
      "Optimizing and evaluating model with ORIGINAL + AUGMENTED data:\n",
      "Best k value: 5\n",
      "Best cross-validation accuracy: 0.9841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acq       0.92      0.89      0.91      2292\n",
      "       crude       0.78      0.93      0.85       374\n",
      "        earn       0.94      0.96      0.95      3923\n",
      "       grain       0.00      0.00      0.00        51\n",
      "    interest       0.74      0.88      0.80       271\n",
      "       money       0.78      0.73      0.75       293\n",
      "        ship       0.00      0.00      0.00       144\n",
      "       trade       0.68      0.88      0.77       326\n",
      "\n",
      "    accuracy                           0.90      7674\n",
      "   macro avg       0.61      0.66      0.63      7674\n",
      "weighted avg       0.88      0.90      0.89      7674\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/matheus/Desktop/Itens/Projetos/paper-weak-llm/weak-llm/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import ollama\n",
    "\n",
    "# 1. Load the dataset\n",
    "dataset_path = \"datasets/original/re8.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# 2. Generate embeddings with Sentence Transformers\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "df[\"embedding\"] = df[\"text\"].apply(lambda x: model.encode(x))\n",
    "\n",
    "# 3. Apply K-Means Clustering\n",
    "def apply_kmeans_clustering(df):\n",
    "    num_clusters = df['class'].nunique()\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "    df['cluster'] = kmeans.fit_predict(df['embedding'].tolist())\n",
    "    distances = euclidean_distances(df['embedding'].tolist(), kmeans.cluster_centers_)\n",
    "    return df, distances, kmeans\n",
    "\n",
    "df, distances, kmeans = apply_kmeans_clustering(df)\n",
    "\n",
    "# 4. Select representative instances\n",
    "def select_representative_instances(df, distances, num_clusters, m):\n",
    "    n = int(m * (len(df) / df['class'].nunique()))\n",
    "    selected_instances = []\n",
    "    for cluster_id in range(num_clusters):\n",
    "        cluster_indices = np.where(df['cluster'] == cluster_id)[0]\n",
    "        cluster_distances = distances[cluster_indices, cluster_id]\n",
    "        sorted_indices = cluster_indices[np.argsort(cluster_distances)]\n",
    "        selected_indices = sorted_indices[:n]\n",
    "        selected_instances.append(df.iloc[selected_indices])\n",
    "    return pd.concat(selected_instances)\n",
    "\n",
    "m = 0.05  # Percentual de dados selecionados\n",
    "df_selected = select_representative_instances(df, distances, df['class'].nunique(), m)\n",
    "display(df_selected)\n",
    "\n",
    "# 5. Data augmentation using Ollama for paraphrasing\n",
    "def paraphrase_text(text, text_class):\n",
    "    prompt = f\"Summarize the following text in English while preserving its key points and clarity. Ensure the summary is concise, coherent, and maintains the original meaning. The text belongs to the following category: {text_class}. Here is the text: {text}.\"\n",
    "    #prompt = f\"Rewrite the following text in English while maintaining its original meaning and improving clarity and fluency. This text belongs to the category: {text_class}. Text: {text}\"\n",
    "    user_prompt = prompt.format(text=text, text_class=text_class)\n",
    "    llm_response = ollama.chat(model='llama3.2:3b', messages=[{'role': 'user', 'content': user_prompt}], options={\n",
    "                    'num_predict': 1000,\n",
    "                    'temperature': 0.1,\n",
    "                    'num_ctx': 8000\n",
    "                })\n",
    "    response = llm_response['message']['content'].strip()\n",
    "    return response \n",
    "\n",
    "df_selected_aug = df_selected.copy()\n",
    "df_selected_aug[\"text\"] = df_selected_aug.apply(lambda row: paraphrase_text(row[\"text\"], row[\"class\"]), axis=1)\n",
    "df_selected_aug[\"embedding\"] = df_selected_aug[\"text\"].apply(lambda x: model.encode(x))\n",
    "\n",
    "# 6. Train-Test Split with selected instances\n",
    "X_train_emb = np.stack(df_selected[\"embedding\"].values)\n",
    "y_train = df_selected[\"class\"].values\n",
    "X_test_emb = np.stack(df[\"embedding\"].values)\n",
    "y_test = df[\"class\"].values\n",
    "\n",
    "X_train_aug_emb = np.stack(df_selected_aug[\"embedding\"].values)\n",
    "y_train_aug = df_selected_aug[\"class\"].values\n",
    "\n",
    "# 7. Optimize KNN\n",
    "def optimize_knn(X_train, y_train):\n",
    "    param_grid = {\"n_neighbors\": [3, 5, 7, 9, 11]}\n",
    "    knn = KNeighborsClassifier()\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=skf, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best k value: {grid_search.best_params_['n_neighbors']}\")\n",
    "    print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# 8. Evaluate Model\n",
    "def evaluate_knn(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Train and evaluate KNN with selected instances\n",
    "print(\"\\nOptimizing and evaluating model with ORIGINAL data:\")\n",
    "best_knn = optimize_knn(X_train_emb, y_train)\n",
    "evaluate_knn(best_knn, X_test_emb, y_test)\n",
    "\n",
    "# Train and evaluate KNN with augmented data\n",
    "print(\"\\nOptimizing and evaluating model with AUGMENTED data:\")\n",
    "best_knn_aug = optimize_knn(X_train_aug_emb, y_train_aug)\n",
    "evaluate_knn(best_knn_aug, X_test_emb, y_test)\n",
    "\n",
    "# Combinar os dados originais e aumentados\n",
    "X_train_combined = np.vstack((X_train_emb, X_train_aug_emb))\n",
    "y_train_combined = np.concatenate((y_train, y_train_aug))\n",
    "\n",
    "# Train and evaluate KNN with combined data\n",
    "print(\"\\nOptimizing and evaluating model with ORIGINAL + AUGMENTED data:\")\n",
    "best_knn_combined = optimize_knn(X_train_combined, y_train_combined)\n",
    "evaluate_knn(best_knn_combined, X_test_emb, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing and evaluating model with ORIGINAL data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k value: 5\n",
      "Best cross-validation accuracy: 0.5111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Baseball       0.19      0.47      0.27       495\n",
      "  Basketball       0.37      0.55      0.44       495\n",
      "     Bowling       0.71      0.86      0.78       495\n",
      "     Cricket       0.57      0.91      0.70       495\n",
      "     Cycling       0.39      0.86      0.54       495\n",
      "  Equestrian       0.86      0.55      0.67       495\n",
      "     Fencing       0.58      0.92      0.71       495\n",
      "      Flying       0.32      0.21      0.26       495\n",
      "    Football       0.43      0.29      0.35       495\n",
      "        Golf       0.82      0.77      0.79       495\n",
      "  Gymnastics       0.74      0.76      0.75       495\n",
      "      Hockey       0.60      0.16      0.26       495\n",
      "    Lacrosse       0.53      0.95      0.68       495\n",
      "     Martial       0.94      0.80      0.86       495\n",
      " Motorsports       0.76      0.30      0.43       495\n",
      "   Paintball       0.88      0.67      0.76       495\n",
      "     Running       0.53      0.25      0.34       495\n",
      "     Skating       0.86      0.72      0.78       495\n",
      "      Soccer       0.70      0.43      0.53       495\n",
      "    Softball       0.51      0.89      0.65       495\n",
      "    Strength       0.73      0.35      0.47       495\n",
      "      Tennis       0.67      0.73      0.70       495\n",
      "       Track       0.58      0.45      0.51       495\n",
      "  Volleyball       0.74      0.27      0.40       495\n",
      "       Water       0.61      0.33      0.43       495\n",
      "      Winter       0.93      0.77      0.84       495\n",
      "   Wrestling       0.73      0.43      0.54       495\n",
      "\n",
      "    accuracy                           0.58     13365\n",
      "   macro avg       0.64      0.58      0.57     13365\n",
      "weighted avg       0.64      0.58      0.57     13365\n",
      "\n",
      "\n",
      "Optimizing and evaluating model with AUGMENTED data:\n",
      "Best k value: 9\n",
      "Best cross-validation accuracy: 0.4815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Baseball       0.26      0.21      0.23       495\n",
      "  Basketball       0.35      0.47      0.40       495\n",
      "     Bowling       0.51      0.92      0.66       495\n",
      "     Cricket       0.64      0.85      0.73       495\n",
      "     Cycling       0.57      0.73      0.64       495\n",
      "  Equestrian       0.89      0.65      0.75       495\n",
      "     Fencing       0.30      0.93      0.46       495\n",
      "      Flying       0.17      0.10      0.13       495\n",
      "    Football       0.53      0.19      0.28       495\n",
      "        Golf       0.66      0.81      0.72       495\n",
      "  Gymnastics       0.81      0.61      0.70       495\n",
      "      Hockey       0.60      0.20      0.30       495\n",
      "    Lacrosse       0.33      0.96      0.50       495\n",
      "     Martial       0.89      0.85      0.87       495\n",
      " Motorsports       0.47      0.42      0.45       495\n",
      "   Paintball       0.79      0.64      0.71       495\n",
      "     Running       0.35      0.25      0.29       495\n",
      "     Skating       0.70      0.71      0.71       495\n",
      "      Soccer       0.75      0.29      0.42       495\n",
      "    Softball       0.42      0.90      0.57       495\n",
      "    Strength       0.70      0.23      0.34       495\n",
      "      Tennis       0.84      0.49      0.62       495\n",
      "       Track       0.53      0.30      0.38       495\n",
      "  Volleyball       0.48      0.14      0.22       495\n",
      "       Water       0.64      0.26      0.37       495\n",
      "      Winter       0.78      0.67      0.72       495\n",
      "   Wrestling       0.52      0.27      0.36       495\n",
      "\n",
      "    accuracy                           0.52     13365\n",
      "   macro avg       0.57      0.52      0.50     13365\n",
      "weighted avg       0.57      0.52      0.50     13365\n",
      "\n",
      "\n",
      "Optimizing and evaluating model with ORIGINAL + AUGMENTED data:\n",
      "Best k value: 3\n",
      "Best cross-validation accuracy: 0.6593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Baseball       0.27      0.59      0.38       495\n",
      "  Basketball       0.37      0.59      0.45       495\n",
      "     Bowling       0.74      0.88      0.80       495\n",
      "     Cricket       0.65      0.82      0.73       495\n",
      "     Cycling       0.37      0.82      0.51       495\n",
      "  Equestrian       0.86      0.59      0.70       495\n",
      "     Fencing       0.58      0.92      0.71       495\n",
      "      Flying       0.26      0.29      0.27       495\n",
      "    Football       0.39      0.23      0.29       495\n",
      "        Golf       0.81      0.76      0.78       495\n",
      "  Gymnastics       0.73      0.71      0.72       495\n",
      "      Hockey       0.53      0.23      0.32       495\n",
      "    Lacrosse       0.59      0.91      0.71       495\n",
      "     Martial       0.93      0.84      0.89       495\n",
      " Motorsports       0.61      0.35      0.45       495\n",
      "   Paintball       0.82      0.69      0.75       495\n",
      "     Running       0.47      0.22      0.30       495\n",
      "     Skating       0.74      0.71      0.73       495\n",
      "      Soccer       0.70      0.45      0.55       495\n",
      "    Softball       0.67      0.89      0.76       495\n",
      "    Strength       0.69      0.47      0.56       495\n",
      "      Tennis       0.80      0.74      0.77       495\n",
      "       Track       0.58      0.38      0.46       495\n",
      "  Volleyball       0.68      0.37      0.48       495\n",
      "       Water       0.65      0.33      0.43       495\n",
      "      Winter       0.87      0.79      0.83       495\n",
      "   Wrestling       0.67      0.51      0.58       495\n",
      "\n",
      "    accuracy                           0.60     13365\n",
      "   macro avg       0.63      0.60      0.59     13365\n",
      "weighted avg       0.63      0.60      0.59     13365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "\n",
    "# 1. Load the dataset\n",
    "dataset_path = \"datasets/original/Dmoz-Sports.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# 2. Generate embeddings with Sentence Transformers\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "df[\"embedding\"] = df[\"text\"].apply(lambda x: model.encode(x))\n",
    "\n",
    "# 3. Select representative instances using Stratified Sampling\n",
    "def stratified_sampling(df, m):\n",
    "    train_df, test_df = train_test_split(df, stratify=df[\"class\"], test_size=1-m, random_state=42)\n",
    "    return train_df, test_df\n",
    "\n",
    "m = 0.01  # Percentual de dados selecionados\n",
    "train_df, test_df = stratified_sampling(df, m)\n",
    "\n",
    "# 4. Data augmentation using Ollama for paraphrasing\n",
    "def paraphrase_text(text, category):\n",
    "    #prompt = f\"Summarize the following text in English while preserving its key points and clarity. Ensure the summary is concise, coherent, and maintains the original meaning. The text belongs to the following category: {category}. Here is the text: {text}.\"\n",
    "    prompt = f\"Rephrase the following text in English while maintaining its original meaning and clarity: {text}. Ensure the wording is natural and fluent.\"\n",
    "    llm_response = ollama.chat(model='llama3.2:3b', messages=[{'role': 'user', 'content': prompt}], options={\n",
    "                    'num_predict': 1000,\n",
    "                    'temperature': 0.1,\n",
    "                    'num_ctx': 8000\n",
    "                })\n",
    "    response = llm_response['message']['content'].strip()\n",
    "    return response \n",
    "\n",
    "df_selected_aug = train_df.copy()\n",
    "df_selected_aug[\"text\"] = train_df.apply(lambda row: paraphrase_text(row[\"text\"], row[\"class\"]), axis=1)\n",
    "df_selected_aug[\"embedding\"] = df_selected_aug[\"text\"].apply(lambda x: model.encode(x))\n",
    "\n",
    "# 5. Train-Test Split with selected instances\n",
    "X_train_emb = train_df[\"embedding\"].tolist()\n",
    "y_train = train_df[\"class\"].tolist()\n",
    "X_test_emb = test_df[\"embedding\"].tolist()\n",
    "y_test = test_df[\"class\"].tolist()\n",
    "\n",
    "X_train_aug_emb = df_selected_aug[\"embedding\"].tolist()\n",
    "y_train_aug = df_selected_aug[\"class\"].tolist()\n",
    "\n",
    "# 6. Optimize KNN\n",
    "def optimize_knn(X_train, y_train):\n",
    "    param_grid = {\"n_neighbors\": [3, 5, 7, 9, 11]}\n",
    "    knn = KNeighborsClassifier()\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=skf, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best k value: {grid_search.best_params_['n_neighbors']}\")\n",
    "    print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# 7. Evaluate Model\n",
    "def evaluate_knn(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Train and evaluate KNN with selected instances\n",
    "print(\"\\nOptimizing and evaluating model with ORIGINAL data:\")\n",
    "best_knn = optimize_knn(X_train_emb, y_train)\n",
    "evaluate_knn(best_knn, X_test_emb, y_test)\n",
    "\n",
    "# Train and evaluate KNN with augmented data\n",
    "print(\"\\nOptimizing and evaluating model with AUGMENTED data:\")\n",
    "best_knn_aug = optimize_knn(X_train_aug_emb, y_train_aug)\n",
    "evaluate_knn(best_knn_aug, X_test_emb, y_test)\n",
    "\n",
    "# Combine original and augmented data\n",
    "X_train_combined = np.vstack((X_train_emb, X_train_aug_emb))\n",
    "y_train_combined = np.concatenate((y_train, y_train_aug))\n",
    "\n",
    "# Train and evaluate KNN with combined data\n",
    "print(\"\\nOptimizing and evaluating model with ORIGINAL + AUGMENTED data:\")\n",
    "best_knn_combined = optimize_knn(X_train_combined, y_train_combined)\n",
    "evaluate_knn(best_knn_combined, X_test_emb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing and evaluating model with ORIGINAL data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k value: 5\n",
      "Best cross-validation accuracy: 0.5111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Baseball       0.19      0.47      0.27       495\n",
      "  Basketball       0.37      0.55      0.44       495\n",
      "     Bowling       0.71      0.86      0.78       495\n",
      "     Cricket       0.57      0.91      0.70       495\n",
      "     Cycling       0.39      0.86      0.54       495\n",
      "  Equestrian       0.86      0.55      0.67       495\n",
      "     Fencing       0.58      0.92      0.71       495\n",
      "      Flying       0.32      0.21      0.26       495\n",
      "    Football       0.43      0.29      0.35       495\n",
      "        Golf       0.82      0.77      0.79       495\n",
      "  Gymnastics       0.74      0.76      0.75       495\n",
      "      Hockey       0.60      0.16      0.26       495\n",
      "    Lacrosse       0.53      0.95      0.68       495\n",
      "     Martial       0.94      0.80      0.86       495\n",
      " Motorsports       0.76      0.30      0.43       495\n",
      "   Paintball       0.88      0.67      0.76       495\n",
      "     Running       0.53      0.25      0.34       495\n",
      "     Skating       0.86      0.72      0.78       495\n",
      "      Soccer       0.70      0.43      0.53       495\n",
      "    Softball       0.51      0.89      0.65       495\n",
      "    Strength       0.73      0.35      0.47       495\n",
      "      Tennis       0.67      0.73      0.70       495\n",
      "       Track       0.58      0.45      0.51       495\n",
      "  Volleyball       0.74      0.27      0.40       495\n",
      "       Water       0.61      0.33      0.43       495\n",
      "      Winter       0.93      0.77      0.84       495\n",
      "   Wrestling       0.73      0.43      0.54       495\n",
      "\n",
      "    accuracy                           0.58     13365\n",
      "   macro avg       0.64      0.58      0.57     13365\n",
      "weighted avg       0.64      0.58      0.57     13365\n",
      "\n",
      "\n",
      "Optimizing and evaluating model with AUGMENTED data:\n",
      "Best k value: 3\n",
      "Best cross-validation accuracy: 0.9956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Baseball       0.40      0.30      0.34       495\n",
      "  Basketball       0.45      0.49      0.47       495\n",
      "     Bowling       0.76      0.89      0.82       495\n",
      "     Cricket       0.71      0.79      0.75       495\n",
      "     Cycling       0.52      0.61      0.56       495\n",
      "  Equestrian       0.82      0.69      0.75       495\n",
      "     Fencing       0.58      0.91      0.71       495\n",
      "      Flying       0.22      0.40      0.28       495\n",
      "    Football       0.46      0.22      0.30       495\n",
      "        Golf       0.75      0.81      0.78       495\n",
      "  Gymnastics       0.84      0.64      0.72       495\n",
      "      Hockey       0.42      0.24      0.31       495\n",
      "    Lacrosse       0.74      0.83      0.78       495\n",
      "     Martial       0.92      0.87      0.89       495\n",
      " Motorsports       0.51      0.55      0.53       495\n",
      "   Paintball       0.85      0.66      0.74       495\n",
      "     Running       0.57      0.25      0.35       495\n",
      "     Skating       0.59      0.67      0.63       495\n",
      "      Soccer       0.70      0.38      0.50       495\n",
      "    Softball       0.58      0.88      0.70       495\n",
      "    Strength       0.68      0.52      0.59       495\n",
      "      Tennis       0.65      0.76      0.70       495\n",
      "       Track       0.52      0.61      0.56       495\n",
      "  Volleyball       0.51      0.53      0.52       495\n",
      "       Water       0.42      0.40      0.41       495\n",
      "      Winter       0.85      0.75      0.80       495\n",
      "   Wrestling       0.61      0.65      0.63       495\n",
      "\n",
      "    accuracy                           0.60     13365\n",
      "   macro avg       0.62      0.60      0.60     13365\n",
      "weighted avg       0.62      0.60      0.60     13365\n",
      "\n",
      "\n",
      "Optimizing and evaluating model with ORIGINAL + AUGMENTED data:\n",
      "Best k value: 3\n",
      "Best cross-validation accuracy: 0.9938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Baseball       0.32      0.43      0.37       495\n",
      "  Basketball       0.44      0.56      0.49       495\n",
      "     Bowling       0.79      0.88      0.83       495\n",
      "     Cricket       0.71      0.82      0.76       495\n",
      "     Cycling       0.42      0.76      0.54       495\n",
      "  Equestrian       0.86      0.65      0.74       495\n",
      "     Fencing       0.65      0.91      0.76       495\n",
      "      Flying       0.25      0.40      0.31       495\n",
      "    Football       0.38      0.23      0.29       495\n",
      "        Golf       0.82      0.78      0.80       495\n",
      "  Gymnastics       0.78      0.70      0.74       495\n",
      "      Hockey       0.47      0.24      0.32       495\n",
      "    Lacrosse       0.66      0.89      0.76       495\n",
      "     Martial       0.93      0.87      0.90       495\n",
      " Motorsports       0.56      0.46      0.51       495\n",
      "   Paintball       0.82      0.68      0.74       495\n",
      "     Running       0.52      0.26      0.35       495\n",
      "     Skating       0.69      0.69      0.69       495\n",
      "      Soccer       0.68      0.43      0.52       495\n",
      "    Softball       0.66      0.88      0.76       495\n",
      "    Strength       0.66      0.52      0.58       495\n",
      "      Tennis       0.71      0.79      0.75       495\n",
      "       Track       0.55      0.51      0.53       495\n",
      "  Volleyball       0.59      0.47      0.52       495\n",
      "       Water       0.49      0.40      0.44       495\n",
      "      Winter       0.86      0.76      0.81       495\n",
      "   Wrestling       0.66      0.60      0.63       495\n",
      "\n",
      "    accuracy                           0.61     13365\n",
      "   macro avg       0.63      0.61      0.61     13365\n",
      "weighted avg       0.63      0.61      0.61     13365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "\n",
    "# 1. Load the dataset\n",
    "dataset_path = \"datasets/original/Dmoz-Sports.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# 2. Generate embeddings with Sentence Transformers\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "df[\"embedding\"] = df[\"text\"].apply(lambda x: model.encode(x))\n",
    "\n",
    "# 3. Select representative instances using Stratified Sampling\n",
    "def stratified_sampling(df, m):\n",
    "    train_df, test_df = train_test_split(df, stratify=df[\"class\"], test_size=1-m, random_state=42)\n",
    "    return train_df, test_df\n",
    "\n",
    "m = 0.01  # Percentual de dados selecionados\n",
    "train_df, test_df = stratified_sampling(df, m)\n",
    "\n",
    "# 4. Data augmentation using Ollama for paraphrasing\n",
    "def paraphrase_text(text, category, seed):\n",
    "    random.seed(seed)\n",
    "    temperature = random.uniform(0.05, 1.0)  # Gera um valor aleatório entre 0.05 e 0.5\n",
    "    prompt = f\"Rephrase the following text in English while maintaining its original meaning and clarity: {text}. Ensure the wording is natural and fluent.\"\n",
    "    llm_response = ollama.chat(model='llama3.2:3b', messages=[{'role': 'user', 'content': prompt}], options={\n",
    "                    'num_predict': 1000,\n",
    "                    'temperature': temperature,\n",
    "                    'num_ctx': 8000\n",
    "                })\n",
    "    response = llm_response['message']['content'].strip()\n",
    "    return response \n",
    "\n",
    "n_augmentations = 5  # Número de vezes que cada dado será aumentado\n",
    "seed_value = 42  # Seed fixa para reprodutibilidade\n",
    "\n",
    "df_augmented_list = []\n",
    "for i in range(n_augmentations):\n",
    "    df_aug = train_df.copy()\n",
    "    df_aug[\"text\"] = train_df.apply(lambda row: paraphrase_text(row[\"text\"], row[\"class\"], seed_value + i), axis=1)\n",
    "    df_aug[\"embedding\"] = df_aug[\"text\"].apply(lambda x: model.encode(x))\n",
    "    df_augmented_list.append(df_aug)\n",
    "\n",
    "df_selected_aug = pd.concat(df_augmented_list, ignore_index=True)\n",
    "\n",
    "# 5. Train-Test Split with selected instances\n",
    "X_train_emb = train_df[\"embedding\"].tolist()\n",
    "y_train = train_df[\"class\"].tolist()\n",
    "X_test_emb = test_df[\"embedding\"].tolist()\n",
    "y_test = test_df[\"class\"].tolist()\n",
    "\n",
    "X_train_aug_emb = df_selected_aug[\"embedding\"].tolist()\n",
    "y_train_aug = df_selected_aug[\"class\"].tolist()\n",
    "\n",
    "# 6. Optimize KNN\n",
    "def optimize_knn(X_train, y_train):\n",
    "    param_grid = {\"n_neighbors\": [3, 5, 7, 9, 11]}\n",
    "    knn = KNeighborsClassifier()\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=skf, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best k value: {grid_search.best_params_['n_neighbors']}\")\n",
    "    print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# 7. Evaluate Model\n",
    "def evaluate_knn(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Train and evaluate KNN with selected instances\n",
    "print(\"\\nOptimizing and evaluating model with ORIGINAL data:\")\n",
    "best_knn = optimize_knn(X_train_emb, y_train)\n",
    "evaluate_knn(best_knn, X_test_emb, y_test)\n",
    "\n",
    "# Train and evaluate KNN with augmented data\n",
    "print(\"\\nOptimizing and evaluating model with AUGMENTED data:\")\n",
    "best_knn_aug = optimize_knn(X_train_aug_emb, y_train_aug)\n",
    "evaluate_knn(best_knn_aug, X_test_emb, y_test)\n",
    "\n",
    "# Combine original and augmented data\n",
    "X_train_combined = np.vstack((X_train_emb, X_train_aug_emb))\n",
    "y_train_combined = np.concatenate((y_train, y_train_aug))\n",
    "\n",
    "# Train and evaluate KNN with combined data\n",
    "print(\"\\nOptimizing and evaluating model with ORIGINAL + AUGMENTED data:\")\n",
    "best_knn_combined = optimize_knn(X_train_combined, y_train_combined)\n",
    "evaluate_knn(best_knn_combined, X_test_emb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_class\n",
       "cacm    7000\n",
       "med       62\n",
       "cran      28\n",
       "cisi       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/llm_predict/zero_shot/classic4/llama3.2:3b.csv\")\n",
    "df['predicted_class'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
